{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from networks.LeNet import LeNet\n",
    "from GTSRB_Reader import GTSRB_Reader\n",
    "from datasets.GTSRB_Dataset import GTSRB_Dataset\n",
    "from adversarial_examples.Adversary_Dataset import Adversary_Dataset\n",
    "from adversarial_examples.Mixed_Dataset import Mixed_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilons : 변형 정도\n",
    "epsilons = [.05, .1]#[.001, .015, .02, .025, .03, .04] # epsilon 0.05도 굉장히 티가 많이 나기 때문에 티가 덜 나는 쪽으로 하기 위해서 추가\n",
    "pretrained_model = './models/LeNet/lenet_GTSRB_net.pth'\n",
    "use_cuda = True\n",
    "\n",
    "NUM_CLASSES = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = datasets.CIFAR10(\n",
    "#     root='./datasets/cifar10/',\n",
    "#     train=True,\n",
    "#     transform=transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "#     ])\n",
    "# )\n",
    "\"\"\" train \n",
    "g = GTSRB_Reader()\n",
    "\n",
    "clean_train_data_examples, _ = g.readTrafficSigns('./datasets/GTSRB/training/Images')\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = Adversary_Dataset(clean_train_data_examples, tf)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1)\n",
    "\n",
    "clean_train_data_examples = []\n",
    "clean_train_label_examples = []\n",
    "for (data, label) in tqdm(data_loader):\n",
    "    clean_train_data_examples.append(data[0])\n",
    "    clean_train_label_examples.append(label[0])\n",
    "\n",
    "clean_train_dataset = Mixed_Dataset(clean_train_data_examples, clean_train_label_examples)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=clean_train_dataset, batch_size=1, shuffle=True)\n",
    "\"\"\"\n",
    "# \"\"\" test\n",
    "g = GTSRB_Reader()\n",
    "\n",
    "clean_test_data_examples, clean_test_label_examples = g.readTestTrafficSigns('./datasets/GTSRB/test/Images/')\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = GTSRB_Dataset(clean_test_data_examples, clean_test_label_examples, tf)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1, shuffle=True)\n",
    "# \"\"\"\n",
    "# dataset = Mixed_Dataset(clean_train_data_examples, clean_train_label_examples)\n",
    "\n",
    "# data_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "model = LeNet(num_classes=NUM_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGSM attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM 공격 코드\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "\n",
    "    sign_data_grad = data_grad.sign()\n",
    "\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    # perturbed_image = torch.clamp(perturbed_image, 0, 1) # for grayscale\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 255)\n",
    "\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, data_loader, epsilon ):\n",
    "    # correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    for data, target in tqdm(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        data.requires_grad = True\n",
    "\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        # if final_pred.item() == target.item():\n",
    "        #     correct += 1\n",
    "            # adv_ex = perturbed_data.cpu()\n",
    "            # adv_examples.append( (target.item(), final_pred.item(), adv_ex) )\n",
    "        \n",
    "        adv_ex = perturbed_data.cpu()\n",
    "        adv_examples.append( (target.item(), adv_ex) )\n",
    "        \n",
    "    # final_acc = correct / 50_000\n",
    "    # print(\"Epsilon: {}\\tTest Accuracy = {}\".format(epsilon, final_acc))\n",
    "\n",
    "    return adv_examples\n",
    "    # 정확도와 적대적 예제를 리턴합니다\n",
    "    # return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12630/12630 [00:55<00:00, 228.89it/s]\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "adv_examples = []\n",
    "\n",
    "ad_ex = test(model, device, data_loader, epsilons[1])\n",
    "adv_examples.append(ad_ex)\n",
    "\n",
    "# for eps in epsilons:\n",
    "#     #acc, ex = test(model, device, test_loader, eps)\n",
    "#     ad_ex = test(model, device, test_loader, eps)\n",
    "#     # accs.append(acc)\n",
    "#     adv_examples.append(ad_ex) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12630/12630 [00:08<00:00, 1450.21it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PATH = './adversarial_examples/'\n",
    "DATASET = 'GTSRB/' # CIFAR10, CIFAR100\n",
    "TYPE = 'test/' # training, test\n",
    "EPSILON = str(epsilons[1])\n",
    "\n",
    "# 각 엡실론에서 적대적 샘플 저장\n",
    "tf = transforms.ToPILImage()\n",
    "\n",
    "# for eps in epsilons:\n",
    "if not os.path.isdir(PATH + DATASET + TYPE + EPSILON):\n",
    "    os.mkdir(PATH + DATASET + TYPE + EPSILON)\n",
    "\n",
    "for i in range(0, NUM_CLASSES):\n",
    "    if not os.path.isdir(PATH + DATASET + TYPE + EPSILON + '/' + str(i)):\n",
    "        os.mkdir(PATH + DATASET + TYPE + EPSILON + '/' + str(i))\n",
    "\n",
    "# for i in range(len(epsilons)):\n",
    "cnt = [0] * NUM_CLASSES\n",
    "for j in tqdm(range(len(adv_examples[0]))):\n",
    "    orig, ex = adv_examples[0][j]\n",
    "    cnt[orig] += 1\n",
    "\n",
    "    tf(ex[0]).save(PATH + DATASET + TYPE + EPSILON  + '/' + str(orig) + '/' + str(cnt[orig]) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36c5b5067bbe9632e3f7d684f53fe7d86d49d88cf9ddc0b52469efeac9d457e9"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('kcse': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}