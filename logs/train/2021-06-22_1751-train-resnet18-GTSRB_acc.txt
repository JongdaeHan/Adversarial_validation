# Hyper-parameter informations
- dataset : GTSRB_acc
- is_pretrained : False
- is_transfered : False
- epochs : 30
- batch_size : 64
- learning_rate : 0.001
- momentum : 0.9
- criterion : crossentropy
- optimizer : sgd

# Logs
1 epoch loss : 1.474
1 epoch acc : 59.95
2 epoch loss : 0.289
2 epoch acc : 92.06
3 epoch loss : 0.105
3 epoch acc : 97.35
4 epoch loss : 0.058
4 epoch acc : 98.67
5 epoch loss : 0.032
5 epoch acc : 99.32
6 epoch loss : 0.023
6 epoch acc : 99.56
7 epoch loss : 0.015
7 epoch acc : 99.72
8 epoch loss : 0.012
8 epoch acc : 99.80
9 epoch loss : 0.011
9 epoch acc : 99.78
10 epoch loss : 0.007
10 epoch acc : 99.90
11 epoch loss : 0.006
11 epoch acc : 99.91
12 epoch loss : 0.006
12 epoch acc : 99.90
13 epoch loss : 0.004
13 epoch acc : 99.94
14 epoch loss : 0.003
14 epoch acc : 99.95
15 epoch loss : 0.003
15 epoch acc : 99.97
16 epoch loss : 0.002
16 epoch acc : 99.98
17 epoch loss : 0.003
17 epoch acc : 99.96
18 epoch loss : 0.002
18 epoch acc : 99.99
19 epoch loss : 0.002
19 epoch acc : 99.99
20 epoch loss : 0.002
20 epoch acc : 99.99
21 epoch loss : 0.001
21 epoch acc : 100.00
22 epoch loss : 0.002
22 epoch acc : 99.97
23 epoch loss : 0.001
23 epoch acc : 99.99
24 epoch loss : 0.001
24 epoch acc : 99.98
25 epoch loss : 0.001
25 epoch acc : 99.98
26 epoch loss : 0.001
26 epoch acc : 100.00
27 epoch loss : 0.002
27 epoch acc : 99.97
28 epoch loss : 0.001
28 epoch acc : 100.00
29 epoch loss : 0.001
29 epoch acc : 100.00
30 epoch loss : 0.002
30 epoch acc : 99.96
