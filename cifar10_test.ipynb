{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python365jvsc74a57bd036c5b5067bbe9632e3f7d684f53fe7d86d49d88cf9ddc0b52469efeac9d457e9",
   "display_name": "Python 3.6.5 64-bit ('kcse': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 데이터 셋을 섞어야 한다.\n",
    "\n",
    "* 용어\n",
    "- clean : original CIFAR10\n",
    "- adv : adversarial CIFAR10\n",
    "- aug : augmented CIFAR10\n",
    "\n",
    "* 방법\n",
    "1. clean(BASELINE)\n",
    "2. clean + adv -> clean : adv = [(90:10), (80:20), (70:30), (60:40)]\n",
    "3. clean + aug -> clean : aug = [(90:10), (80:20), (70:30), (60:40)]\n",
    "4. clean + adv + aug -> 미정"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms, utils\n",
    "import torchvision.models as models\n",
    "\n",
    "import os, random\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from options.train_options import TrainOptions\n",
    "from networks.LeNet import LeNet\n",
    "from utils.Logger import Logger"
   ]
  },
  {
   "source": [
    "## Load clean examples(original datasets)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### clean test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 822.37it/s]\n",
      "tensor([2])\n",
      "tensor([[[[-0.1451, -0.1529, -0.1373,  ..., -0.0353, -0.0431, -0.0353],\n",
      "          [-0.1451, -0.1451, -0.1373,  ..., -0.0118, -0.0275, -0.0039],\n",
      "          [-0.1216, -0.1216, -0.1137,  ...,  0.0196,  0.0118,  0.0353],\n",
      "          ...,\n",
      "          [-0.0980, -0.1059, -0.1059,  ...,  0.1686,  0.1922,  0.0824],\n",
      "          [-0.1216, -0.1216, -0.1059,  ...,  0.3725,  0.0980, -0.0824],\n",
      "          [-0.0980, -0.0980, -0.0824,  ..., -0.0431, -0.3333, -0.3020]],\n",
      "\n",
      "         [[-0.0431, -0.0510, -0.0431,  ..., -0.0196, -0.0275, -0.0118],\n",
      "          [-0.0353, -0.0431, -0.0353,  ...,  0.0039, -0.0118,  0.0118],\n",
      "          [-0.0196, -0.0196, -0.0118,  ...,  0.0353,  0.0275,  0.0510],\n",
      "          ...,\n",
      "          [ 0.0275,  0.0039, -0.0118,  ...,  0.2157,  0.2392,  0.1373],\n",
      "          [ 0.0039, -0.0118, -0.0118,  ...,  0.4118,  0.1294, -0.0588],\n",
      "          [ 0.0039, -0.0039, -0.0039,  ..., -0.0196, -0.3098, -0.2941]],\n",
      "\n",
      "         [[-0.5765, -0.5843, -0.5765,  ..., -0.4118, -0.4275, -0.4275],\n",
      "          [-0.5843, -0.5843, -0.5765,  ..., -0.3804, -0.4039, -0.3804],\n",
      "          [-0.5765, -0.5608, -0.5608,  ..., -0.3569, -0.3569, -0.3412],\n",
      "          ...,\n",
      "          [-0.5529, -0.5608, -0.5765,  ..., -0.1294, -0.0824, -0.2235],\n",
      "          [-0.5765, -0.5765, -0.5686,  ...,  0.2235, -0.0745, -0.3255],\n",
      "          [-0.5686, -0.5686, -0.5608,  ..., -0.0824, -0.4118, -0.4824]]]])\n"
     ]
    }
   ],
   "source": [
    "clean_test_examples = []\n",
    "\n",
    "clean_test_dataset = datasets.CIFAR10(\n",
    "    root='./datasets/cifar10/',\n",
    "    train=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    ])\n",
    ")\n",
    "\n",
    "clean_test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=clean_test_dataset, batch_size=1, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "for (data, label) in tqdm(clean_test_loader):\n",
    "    clean_test_examples.append((data, label))\n",
    "\n",
    "# for (data, label) in clean_test_examples:\n",
    "#     print(label)\n",
    "#     print(data)\n",
    "#     break\n"
   ]
  },
  {
   "source": [
    "## Load adversarial examples\n",
    "### get adversarial examples\n",
    "- adv_examples : 적대적 예시 리스트 [(data, labels), ..., ]\n",
    "  - data : 이미지가 ToTensor()에 의해 tensor화 된 것\n",
    "  - labels : 이미지에 대한 ground truth, Tensor([라벨])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### adversary test set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3779.15it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3820.04it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3752.39it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3758.53it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3910.34it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3895.44it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3785.87it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3695.52it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3686.46it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3737.63it/s]tensor([8])\n",
      "tensor([[[0.4314, 0.4941, 0.5137,  ..., 0.4314, 0.3922, 0.4235],\n",
      "         [0.4863, 0.5255, 0.5333,  ..., 0.4314, 0.3882, 0.4118],\n",
      "         [0.4863, 0.5020, 0.4863,  ..., 0.4392, 0.3882, 0.3961],\n",
      "         ...,\n",
      "         [0.0118, 0.0118, 0.0314,  ..., 0.0235, 0.0000, 0.1216],\n",
      "         [0.0000, 0.0000, 0.0314,  ..., 0.0000, 0.0000, 0.0824],\n",
      "         [0.0118, 0.0000, 0.0000,  ..., 0.0000, 0.0078, 0.0706]],\n",
      "\n",
      "        [[0.5843, 0.6471, 0.6588,  ..., 0.5961, 0.5569, 0.5882],\n",
      "         [0.6431, 0.6824, 0.6824,  ..., 0.5961, 0.5529, 0.5765],\n",
      "         [0.6431, 0.6588, 0.6353,  ..., 0.6039, 0.5529, 0.5647],\n",
      "         ...,\n",
      "         [0.1529, 0.1529, 0.1725,  ..., 0.0784, 0.0314, 0.1608],\n",
      "         [0.1176, 0.1255, 0.1569,  ..., 0.0549, 0.0431, 0.1255],\n",
      "         [0.1294, 0.0980, 0.0980,  ..., 0.0471, 0.0627, 0.1176]],\n",
      "\n",
      "        [[0.6431, 0.7059, 0.7216,  ..., 0.6510, 0.6118, 0.6431],\n",
      "         [0.6902, 0.7294, 0.7333,  ..., 0.6588, 0.6078, 0.6314],\n",
      "         [0.6745, 0.6902, 0.6706,  ..., 0.6667, 0.6157, 0.6275],\n",
      "         ...,\n",
      "         [0.2157, 0.2157, 0.2353,  ..., 0.0196, 0.0000, 0.0667],\n",
      "         [0.2000, 0.2078, 0.2392,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2235, 0.1922, 0.1922,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf = transforms.ToTensor()\n",
    "\n",
    "ADV_TEST_DIR = './adversarial_examples/CIFAR10/test/'\n",
    "\n",
    "# label\n",
    "classes = os.listdir(ADV_TEST_DIR + '0.05/')\n",
    "\n",
    "adv_test_examples = []\n",
    "\n",
    "i = 0\n",
    "for _class in classes:\n",
    "    # print('\\n' + _class, ' processing')\n",
    "    # images\n",
    "    train_images = os.listdir(ADV_TEST_DIR + '0.05/' + _class + '/')\n",
    "    for image in tqdm(train_images):\n",
    "        data = Image.open(ADV_TEST_DIR + '0.05/' + _class + '/' + image)\n",
    "        data = tf(data)\n",
    "\n",
    "        label = torch.tensor(np.array([int(_class)]))\n",
    "        adv_test_examples.append( (data, label) )\n",
    "\n",
    "# for shuffling check\n",
    "# print(adv_test_examples[0][1])\n",
    "# print(adv_test_examples[9_999][1])\n",
    "\n",
    "# load data loader\n",
    "# adv_test_loader = torch.utils.data.DataLoader(\n",
    "#     dataset=adv_test_examples, batch_size=1, shuffle=True, num_workers=2\n",
    "# )\n",
    "\n",
    "# for (data, label) in adv_test_examples:\n",
    "#     print(label)\n",
    "#     print(data)\n",
    "#     break"
   ]
  },
  {
   "source": [
    "### shuffle the adversarial examples\n",
    "- 라벨 별로 들어 있는 적대적 예시 배열을 랜덤하게 섞는다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "random.shuffle(adv_test_examples)\n",
    "\n",
    "print(adv_test_examples[0][1])\n",
    "print(adv_test_examples[9_999][1])"
   ]
  },
  {
   "source": [
    "### create mixed datasets\n",
    "- clean의 일부와 adversary의 일부를 +로 합친다.\n",
    "    ```\n",
    "    clean+adv = clean[:int(len(clean) * 0.8)] + adv[:(int)len(adv) * 0.2]\n",
    "    shuffle clean + adv\n",
    "    ```\n",
    "- 섞은 것을 학습에 활용한다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix test\n",
    "mixed_test_dataset = clean_test_examples[:int(len(clean_test_examples) * 0.8)] + adv_test_examples[:int(len(adv_test_examples) * 0.2)]\n",
    "# random.shuffle(mixed_test_dataset)"
   ]
  },
  {
   "source": [
    "### make mixed data loader"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "mixed_test_loader = torch.utils.data.DataLoader(\n",
    "    mixed_test_dataset, batch_size=64, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "source": [
    "## Train\n",
    "- 새로 합성한 데이터 셋을 활용해서 학습 진행\n",
    "- TODO :: data loader 두 개 섞기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "    print('Training will be activated in', DEVICE)\n",
    "\n",
    "    NETWORK = 'lenet'\n",
    "    # DATASET = opt.dataset\n",
    "    SAVE_DIR = './models/LeNet/'\n",
    "    NUM_CLASSES = 10\n",
    "\n",
    "    IS_PRETRAINED = False\n",
    "    IS_TRANSFERED = False\n",
    "\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 64\n",
    "    LEARNING_RATE = 0.001\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    CRITERION = 'crossentropy'\n",
    "    OPTIMIZER = 'sgd'\n",
    "\n",
    "    logger = Logger(model=NETWORK, dataset='adversary cifar10')\n",
    "    hyper_parameter_infos = \"\"\"\\\n",
    "    - is_pretrained : %s\n",
    "    - is_transfered : %s\n",
    "    - epochs : %s\n",
    "    - batch_size : %s\n",
    "    - learning_rate : %s\n",
    "    - momentum : %s\n",
    "    - criterion : %s\n",
    "    - optimizer : %s\\\n",
    "    \"\"\" % (IS_PRETRAINED, IS_TRANSFERED, EPOCHS, BATCH_SIZE, LEARNING_RATE, MOMENTUM, CRITERION, OPTIMIZER)\n",
    "    logs = ''\n",
    "\n",
    "    # models : lenet5, resnet18, vgg16\n",
    "    if NETWORK == 'lenet':\n",
    "        model = LeNet(num_classes=NUM_CLASSES)\n",
    "    if NETWORK == 'resnet18':\n",
    "        model = models.resnet18(pretrained=IS_PRETRAINED,\n",
    "                                num_classes=NUM_CLASSES)\n",
    "    if NETWORK == 'vgg16':\n",
    "        model = models.vgg16(pretrained=IS_PRETRAINED, num_classes=NUM_CLASSES)\n",
    "\n",
    "    print(NETWORK + ' will be used')\n",
    "    print(hyper_parameter_infos)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    if CRITERION == 'crossentropy':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    if CRITERION == 'mseloss':\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "    if OPTIMIZER == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                              lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "    if OPTIMIZER == 'adam':\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # print('%d epoch started' % epoch)\n",
    "        running_loss = .0\n",
    "        for _, (data, target) in enumerate(mixed_train_loader):\n",
    "            data[0], target = data.to(DEVICE), target.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print('%d epoch loss : %.3f' %\n",
    "              (epoch + 1, running_loss / len(mixed_train_loader)))\n",
    "        logs += '%d epoch loss : %.3f' % (epoch + 1,\n",
    "                                          running_loss / len(mixed_train_loader)) + '\\n'\n",
    "\n",
    "    # use last epoch only\n",
    "    torch.save(model.state_dict(), SAVE_DIR + NETWORK + '_adversary_cifar10' + '_net.pth')\n",
    "    logger.create_txt(hyper_parameter_infos, logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}